{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb33e352-a65d-40e1-b302-9aaca466255d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random\n",
    "from collections import deque\n",
    "from glob import glob\n",
    "\n",
    "import cv2\n",
    "import gradio as gr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch as th\n",
    "import torch.distributed as dist\n",
    "from einops import rearrange\n",
    "from inference import create_argparser\n",
    "from PIL import Image\n",
    "from pretrained_diffusion import dist_util\n",
    "from pretrained_diffusion.glide_util import sample\n",
    "from pretrained_diffusion.image_datasets_sketch import get_tensor\n",
    "from pretrained_diffusion.script_util import (add_dict_to_argparser,\n",
    "                                              args_to_dict,\n",
    "                                              create_model_and_diffusion,\n",
    "                                              model_and_diffusion_defaults)\n",
    "from torchvision.utils import make_grid\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c267e72d-5eb2-4b66-bdd1-5517ac557dc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fix_seed(seed=23333):\n",
    "\n",
    "    if dist.is_initialized():\n",
    "        seed = seed + dist.get_rank()\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)  # CPU随机种子确定\n",
    "    torch.cuda.manual_seed(seed)  # GPU随机种子确定\n",
    "    torch.cuda.manual_seed_all(seed)  # 所有的GPU设置种子\n",
    "\n",
    "    torch.backends.cudnn.benchmark = False  # 模型卷积层预先优化关闭\n",
    "    torch.backends.cudnn.deterministic = True  # 确定为默认卷积算法\n",
    "\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a276a024-2300-40df-8a67-91ad2d01ecb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_image(image_path):\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    return np.array(image)\n",
    "\n",
    "def mark_paths(image, label):\n",
    "    rows, cols, _ = image.shape\n",
    "    visited = np.zeros((rows, cols), dtype=bool)\n",
    "    \n",
    "    def is_white(pixel):\n",
    "        return all(pixel == [255, 255, 255])\n",
    "\n",
    "    def bfs(x, y):\n",
    "        queue = deque([(x, y)])\n",
    "        while queue:\n",
    "            x, y = queue.popleft()\n",
    "            # print(f'{x = }, {y = }')\n",
    "            if visited[x, y] or is_white(image[x, y]):\n",
    "                continue\n",
    "            visited[x, y] = True\n",
    "            image[x, y] = [255, 0, 0]  # Mark as red  \n",
    "            if x > 0: queue.append((x - 1, y))\n",
    "            if x < rows - 1: queue.append((x + 1, y))\n",
    "            if y > 0: queue.append((x, y - 1))\n",
    "            if y < cols - 1: queue.append((x, y + 1))\n",
    "\n",
    "    # Iterate over the boundary\n",
    "    for x in range(rows):\n",
    "        for px, py in ((x, 0), (x, cols - 1)):\n",
    "            is_border = all(\n",
    "                [\n",
    "                    any([is_white(image[xx, py]) for xx in range(0, px)]), \n",
    "                    any([is_white(image[xx, py]) for xx in range(px+1, rows)]),\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            # print('px, py', px, py)\n",
    "            if not is_border:\n",
    "                bfs(px, py)\n",
    "    for y in range(cols):\n",
    "        for px, py in ((0, y), (rows - 1, y)):\n",
    "            is_border = all(\n",
    "                [\n",
    "                    any([is_white(image[px, yy]) for yy in range(0, py)]), \n",
    "                    any([is_white(image[px, yy]) for yy in range(py+1, cols)]),\n",
    "                ]\n",
    "            )\n",
    "            if not is_border:\n",
    "                bfs(px, py)\n",
    "\n",
    "    # Mark all non-visited (and non-white) pixels as red\n",
    "    if label == 'RI':\n",
    "        mark_color = [0, 0, 255]# Mark as blue\n",
    "    elif label == 'RO':\n",
    "        mark_color = [0, 255, 0]# Mark as green\n",
    "    else:\n",
    "        raise ValueError(f'No label: {label}')\n",
    "        \n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            if not visited[i, j]:\n",
    "                image[i, j] = mark_color\n",
    "\n",
    "    return image\n",
    "\n",
    "def process_image(image_path, output_path, label):\n",
    "    image = load_image(image_path)\n",
    "    result_image = mark_paths(image, label)\n",
    "    result = Image.fromarray(result_image)\n",
    "    result.save(output_path)  # Save the result as a PNG file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36d0ca6-00b3-4111-9dbd-369d1d4b304c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_c = 1.4\n",
    "num_samples = 1\n",
    "sample_step = 1000\n",
    "mode = 'mask'\n",
    "\n",
    "parser, parser_up = create_argparser()\n",
    "args = parser.parse_known_args()[0]\n",
    "args_up = parser_up.parse_known_args()[0]\n",
    "dist_util.setup_dist()\n",
    "\n",
    "if mode == 'sketch':\n",
    "    args.mode = 'coco-edge'\n",
    "    args_up.mode = 'coco-edge'\n",
    "    args.model_path = './ckpt/base_edge.pt'\n",
    "    args.sr_model_path = './ckpt/upsample_edge.pt'\n",
    "\n",
    "elif mode == 'mask':\n",
    "    args.mode = 'coco'\n",
    "    args_up.mode = 'coco'\n",
    "    # args.model_path = './logs/coco-mask/coco-64-stage1/checkpoints/ema_0.9999_020000.pt'\n",
    "    # args.model_path = './logs/coco-mask/coco-64-stage1-cont/checkpoints/ema_0.9999_015000.pt'\n",
    "    args.model_path = './logs/coco-mask/coco-64-stage2-decoder/checkpoints/ema_0.9999_015000.pt'\n",
    "    args.sr_model_path = './ckpt/upsample_mask.pt'\n",
    "\n",
    "\n",
    "# args.val_data_dir = image\n",
    "args.sample_c = sample_c\n",
    "args.num_samples = num_samples\n",
    "\n",
    "\n",
    "options=args_to_dict(args, model_and_diffusion_defaults(0.).keys())\n",
    "model, diffusion = create_model_and_diffusion(**options)\n",
    "\n",
    "options_up=args_to_dict(args_up, model_and_diffusion_defaults(True).keys())\n",
    "model_up, diffusion_up = create_model_and_diffusion(**options_up)\n",
    "\n",
    "\n",
    "if  args.model_path:\n",
    "    print('loading model', args.model_path)\n",
    "    model_ckpt = dist_util.load_state_dict(args.model_path, map_location=\"cpu\")\n",
    "\n",
    "    model.load_state_dict(\n",
    "        model_ckpt, strict=True )\n",
    "\n",
    "if  args.sr_model_path:\n",
    "    model_ckpt2 = dist_util.load_state_dict(args.sr_model_path, map_location=\"cpu\")\n",
    "\n",
    "    model_up.load_state_dict(\n",
    "        model_ckpt2, strict=True ) \n",
    "\n",
    "\n",
    "model.to(dist_util.dev())\n",
    "model_up.to(dist_util.dev())\n",
    "model.eval()\n",
    "model_up.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1cee5e-43c9-46df-8183-c553804a66ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_name = f'output-{sample_c}SampleStep{sample_step}'\n",
    "test_data_dir = '../../../影像資料生成競賽/test_dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff3c796-693d-4286-85a0-c015331c3ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dir = os.path.join(test_data_dir, 'label_img')\n",
    "output_dir = os.path.join(test_data_dir, output_name)\n",
    "output_resize_dir = os.path.join(test_data_dir, f'{output_name}-resized')\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "os.makedirs(output_resize_dir, exist_ok=True)\n",
    "\n",
    "label_img_paths = sorted(glob(os.path.join(label_dir, '*')))\n",
    "len(label_img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08476455-cf53-4ccf-902f-200cfb0571a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for label_img_path in tqdm(label_img_paths, total=len(label_img_paths)):\n",
    "    img_name = os.path.basename(label_img_path)\n",
    "    img_class = img_name.split('_')[1]\n",
    "    \n",
    "    output_path = os.path.join(output_dir, img_name).replace('.png', '.jpg')\n",
    "    output_resize_path = os.path.join(output_resize_dir, img_name).replace('.png', '.jpg')\n",
    "\n",
    "    if not os.path.exists(output_resize_path):\n",
    "        name, ext = os.path.splitext(label_img_path)\n",
    "        preprocessed_img_path = f'{name}_mask{ext}'\n",
    "\n",
    "        process_image(label_img_path, preprocessed_img_path, img_class)\n",
    "\n",
    "        image = Image.open(preprocessed_img_path)\n",
    "\n",
    "        ########### dataset\n",
    "        # logger.log(\"creating data loader...\")\n",
    "\n",
    "        if args.mode == 'coco':\n",
    "            pil_image = image  \n",
    "            label_pil = pil_image.convert(\"RGB\").resize((256, 256), Image.NEAREST)\n",
    "            # print('label_pil', type(label_pil), label_pil)\n",
    "            label_tensor =  get_tensor()(label_pil)\n",
    "            # print('label_tensor', label_tensor.shape)\n",
    "\n",
    "            data_dict = {\"ref\":label_tensor.unsqueeze(0).repeat(args.num_samples, 1, 1, 1)}\n",
    "            # print('data_dict.ref.shape', data_dict['ref'].shape)\n",
    "\n",
    "        elif args.mode == 'coco-edge':\n",
    "            # pil_image = Image.open(image)\n",
    "            pil_image = image  \n",
    "            label_pil = pil_image.convert(\"L\").resize((256, 256), Image.NEAREST)\n",
    "\n",
    "            im_dist = cv2.distanceTransform(255-np.array(label_pil), cv2.DIST_L1, 3)\n",
    "            im_dist = np.clip((im_dist) , 0, 255).astype(np.uint8)\n",
    "            im_dist = Image.fromarray(im_dist).convert(\"RGB\")\n",
    "\n",
    "            label_tensor =  get_tensor()(im_dist)[:1]\n",
    "\n",
    "            data_dict = {\"ref\":label_tensor.unsqueeze(0).repeat(args.num_samples, 1, 1, 1)}\n",
    "\n",
    "        # print(\"sampling...\")\n",
    "\n",
    "        sampled_imgs = []\n",
    "        grid_imgs = []\n",
    "        img_id = 0\n",
    "        while (True):\n",
    "            if img_id >= args.num_samples:\n",
    "                break\n",
    "\n",
    "            model_kwargs = data_dict\n",
    "            with th.no_grad():\n",
    "                samples_lr =sample(\n",
    "                    glide_model= model,\n",
    "                    glide_options= options,\n",
    "                    side_x= 64,\n",
    "                    side_y= 64,\n",
    "                    prompt=model_kwargs,\n",
    "                    batch_size= args.num_samples,\n",
    "                    guidance_scale=args.sample_c,\n",
    "                    device=dist_util.dev(),\n",
    "                    prediction_respacing= str(sample_step),\n",
    "                    upsample_enabled= False,\n",
    "                    upsample_temp=0.997,\n",
    "                    mode = args.mode,\n",
    "                )\n",
    "\n",
    "                samples_lr = samples_lr.clamp(-1, 1)\n",
    "\n",
    "                tmp = (127.5*(samples_lr + 1.0)).int() \n",
    "                model_kwargs['low_res'] = tmp/127.5 - 1.\n",
    "\n",
    "                samples_hr =sample(\n",
    "                    glide_model= model_up,\n",
    "                    glide_options= options_up,\n",
    "                    side_x=256,\n",
    "                    side_y=256,\n",
    "                    prompt=model_kwargs,\n",
    "                    batch_size=args.num_samples,\n",
    "                    guidance_scale=1,\n",
    "                    device=dist_util.dev(),\n",
    "                    prediction_respacing= \"fast27\",\n",
    "                    upsample_enabled=True,\n",
    "                    upsample_temp=0.997,\n",
    "                    mode = args.mode,\n",
    "                )\n",
    "\n",
    "\n",
    "                samples_hr = samples_hr \n",
    "\n",
    "\n",
    "                for hr in samples_hr:\n",
    "\n",
    "                    hr = 255. * rearrange((hr.cpu().numpy()+1.0)*0.5, 'c h w -> h w c')\n",
    "                    sample_img = Image.fromarray(hr.astype(np.uint8))\n",
    "                    sampled_imgs.append(sample_img)\n",
    "                    img_id += 1   \n",
    "\n",
    "                grid_imgs.append(samples_hr)\n",
    "\n",
    "        grid = torch.stack(grid_imgs, 0)\n",
    "        grid = rearrange(grid, 'n b c h w -> (n b) c h w')\n",
    "        grid = make_grid(grid, nrow=2)\n",
    "        # to image\n",
    "        grid = 255. * rearrange((grid+1.0)*0.5, 'c h w -> h w c').cpu().numpy()\n",
    "\n",
    "        output_img = Image.fromarray(grid.astype(np.uint8)) \n",
    "        output_img.save(output_path)\n",
    "        output_img = output_img.resize(image.size, Image.NEAREST)\n",
    "        output_img.save(output_resize_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ed5c33-65dc-40a5-a96e-dcb6eed86c9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PITI",
   "language": "python",
   "name": "piti"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
